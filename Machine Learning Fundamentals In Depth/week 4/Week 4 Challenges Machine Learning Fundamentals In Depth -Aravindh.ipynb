{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255a632e",
   "metadata": {},
   "source": [
    "1.Derive log loss Gradient Descent on paper and replicate in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae27d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cae8ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_1638945638.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f4f40d0b4dbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_1638945638.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_1638945638.csv'"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae52c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df.iloc[:, 2]\n",
    "y1 = df.iloc[:, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5574bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1 ,y1,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c022fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x1):\n",
    "    return x1 - x1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1, b0, b1):\n",
    "    return np.array([1 / (1 + exp(-1*b0 + -1*b1*X)) for X in x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss_Gradient_descent(x1, y1,learning_rate,iterations):\n",
    "    X1 = normalize(x1)\n",
    "    b0 = 0\n",
    "    b1 = 0\n",
    "    n = len(x1)\n",
    "    cost_list=[]\n",
    "    for i in range(iterations):\n",
    "        y_pred = predict(X1, b0, b1)\n",
    "        D_b0 = 1/n*sum((y_pred-y1)) # Derivative of loss wrt b0\n",
    "        D_b1 = 1/n*sum(X1 *( y_pred-y1))# Derivative of loss wrt b1\n",
    "        cost = -1/n*sum(y1*np.log(y_pred)+(1-y1)*np.log(1-y_pred))\n",
    "        b0 = b0 - learning_rate * D_b0         # Updating b0 and b1\n",
    "        b1 = b1 - learning_rate * D_b1\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        if(i%(iterations/10) == 0):\n",
    "            print(\"cost after \", i, \"iteration is : \", cost)\n",
    "    return b0, b1,cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "iterations =10000\n",
    "b0,b0,cost_list = LogLoss_Gradient_descent(x1_train, y1_train,learning_rate = learning_rate, iterations = iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2f749",
   "metadata": {},
   "source": [
    "Cost vs Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(iterations), cost_list)\n",
    "plt.xlabel('no_of_iteration')\n",
    "plt.ylabel('cost_function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a195e8",
   "metadata": {},
   "source": [
    "2.What are the different loss functions for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3487d",
   "metadata": {},
   "source": [
    "word file attached for this questions mam/sir.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c222a3",
   "metadata": {},
   "source": [
    "3.When to use one hot encoding\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08aee0",
   "metadata": {},
   "source": [
    "We should prefer using the One Hot Encoding method when : The categorical features present in the data is not ordinal \n",
    "(like the countries above) When the number of categorical features present in the dataset is less so that the one-hot encoding \n",
    "technique can be effectively applied while building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d922e",
   "metadata": {},
   "source": [
    "4.What is dummy variable trap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d94c4",
   "metadata": {},
   "source": [
    "Dummy Variable Trap: \n",
    "    \n",
    "The Dummy variable trap is a scenario where there are attributes that are highly correlated (Multicollinear) and one variable\n",
    "predicts the value of others. When we use one-hot encoding for handling the categorical data, then one dummy variable \n",
    "(attribute) can be predicted with the help of other dummy variables. Hence, one dummy variable is highly correlated with other\n",
    "dummy variables. Using all dummy variables for regression models leads to a dummy variable trap. So, the regression models \n",
    "should be designed to exclude one dummy variable. \n",
    "\n",
    "For Example – \n",
    "Let’s consider the case of gender having two values male (0 or 1) and female (1 or 0). Including both the dummy variable can \n",
    "cause redundancy because if a person is not male in such case that person is a female, hence, we don’t need to use both the \n",
    "variables in regression models. This will protect us from the dummy variable trap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15655397",
   "metadata": {},
   "source": [
    "5.List down the differences between linear and logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b341f",
   "metadata": {},
   "source": [
    "Linear Regression   Logistic Regression\n",
    "Linear Regression is a supervised regression model.\n",
    "Logistic Regression is a supervised classification model.\n",
    "In Linear Regression, we predict the value by an integer number.\n",
    "In Logistic Regression, we predict the value by 1 or 0.\n",
    "Here no activation function is used.\n",
    "Here activation function is used to convert a linear regression equation to the logistic regression equation\n",
    "Here no threshold value is needed.\n",
    "Here a threshold value is added.\n",
    "Here we calculate Root Mean Square Error(RMSE) to predict the next weight value.\n",
    "Here we use precision to predict the next weight value.\n",
    "Here dependent variable should be numeric and the response variable is continuous to value.\tHere the dependent variable consists of only two categories. Logistic regression estimates the odds outcome of the dependent variable given a set of quantitative or categorical independent variables.\n",
    "It is based on the least square estimation.\n",
    "It is based on maximum likelihood estimation.\n",
    "Here when we plot the training datasets, a straight line can be drawn that touches maximum plots.\n",
    "Any change in the coefficient leads to a change in both the direction and the steepness of the logistic function. It means positive slopes result in an S-shaped curve and negative slopes result in a Z-shaped curve.\n",
    "Linear regression is used to estimate the dependent variable in case of a change in independent variables. For example, predict the price of houses.\n",
    "Whereas logistic regression is used to calculate the probability of an event. For example, classify if tissue is benign or malignant.\n",
    "Linear regression assumes the normal or gaussian distribution of the dependent variable.\n",
    "Logistic regression assumes the binomial distribution of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e3e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
